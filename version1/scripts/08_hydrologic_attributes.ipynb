{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170e38bd",
   "metadata": {
    "papermill": {
     "duration": 0.006377,
     "end_time": "2024-05-13T13:54:43.014044",
     "exception": false,
     "start_time": "2024-05-13T13:54:43.007667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hydrologic attributes\n",
    "\n",
    "Notebook to create the file `CAMELS_DE_hydrologic_attributes.csv`.\n",
    "\n",
    "columns:\n",
    "- gauge_id\n",
    "- q_mean [mm/d]\n",
    "- runoff_ratio [-]\n",
    "- flow_period_start\n",
    "- flow_period_end\n",
    "- flow_perc_complete [-]\n",
    "- slope_fdc [-]\n",
    "- hfd_mean [days]\n",
    "- Q5 [mm/d]\n",
    "- Q95 [mm/d]\n",
    "- high_q_freq [days/year]\n",
    "- high_q_dur [days]\n",
    "- low_q_freq [days/year]\n",
    "- low_q_dur [days]\n",
    "- zero_q_freq [-]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa8d009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:54:43.032373Z",
     "iopub.status.busy": "2024-05-13T13:54:43.031992Z",
     "iopub.status.idle": "2024-05-13T13:54:43.227554Z",
     "shell.execute_reply": "2024-05-13T13:54:43.226853Z"
    },
    "papermill": {
     "duration": 0.206441,
     "end_time": "2024-05-13T13:54:43.229588",
     "exception": false,
     "start_time": "2024-05-13T13:54:43.023147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167ce08a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:54:43.242960Z",
     "iopub.status.busy": "2024-05-13T13:54:43.242772Z",
     "iopub.status.idle": "2024-05-13T13:54:43.249978Z",
     "shell.execute_reply": "2024-05-13T13:54:43.249368Z"
    },
    "papermill": {
     "duration": 0.017865,
     "end_time": "2024-05-13T13:54:43.250947",
     "exception": false,
     "start_time": "2024-05-13T13:54:43.233082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations in CAMELS-DE v1: 1460\n"
     ]
    }
   ],
   "source": [
    "# get camels_ids from hydromet timeseries\n",
    "camels_ids = [camels_id.split(\"_\")[-1].split(\".csv\")[0] for camels_id in glob(\"../output_data/camels_de/timeseries/*.csv\")]\n",
    "\n",
    "# sort camels_ids\n",
    "camels_ids = sorted(camels_ids)\n",
    "\n",
    "print(f\"Total number of stations in CAMELS-DE v1: {len(camels_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce6e67",
   "metadata": {
    "papermill": {
     "duration": 0.001821,
     "end_time": "2024-05-13T13:54:43.254754",
     "exception": false,
     "start_time": "2024-05-13T13:54:43.252933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create the file `CAMELS_DE_hydrologic_attributes.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d1840c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:54:43.259288Z",
     "iopub.status.busy": "2024-05-13T13:54:43.259151Z",
     "iopub.status.idle": "2024-05-13T13:54:43.264055Z",
     "shell.execute_reply": "2024-05-13T13:54:43.263492Z"
    },
    "papermill": {
     "duration": 0.008334,
     "end_time": "2024-05-13T13:54:43.264986",
     "exception": false,
     "start_time": "2024-05-13T13:54:43.256652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_complete_hydro_years(df, tolerance=0.05):\n",
    "    \"\"\"\n",
    "    Helper function to filter a DataFrame to only include complete hydrological \n",
    "    years (October - September). A hydrological year is considered complete if \n",
    "    it has less than the specified tolerance of missing values.\n",
    "\n",
    "    \"\"\"\n",
    "    # if date is not in index, set it as index\n",
    "    if 'date' in df.columns:\n",
    "        df = df.set_index('date')\n",
    "\n",
    "    # convert the index to datetime if it is not already\n",
    "    if not isinstance(df.index, pd.DatetimeIndex): \n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # make the dataframe start at the beginning of the hydrological year, i.e. 01.10. of the previous year\n",
    "    min_year = df.index.year.min()\n",
    "    df = df.reindex(pd.date_range(start=f\"{min_year-1}-10-01\", end=df.index.max(), freq='D'))\n",
    "\n",
    "    # make the dataframe end at the end of the hydrological year, i.e. 30.09. of the next year\n",
    "    max_year = df.index.year.max()\n",
    "    df = df.reindex(pd.date_range(start=df.index.min(), end=f\"{max_year+1}-09-30\", freq='D'))\n",
    "\n",
    "    # Calculate the number of missing values per hydrological year for 'discharge_vol' column\n",
    "    df['hydro_year'] = df.index.year\n",
    "    df.loc[df.index.month >= 10, 'hydro_year'] += 1\n",
    "    missing_values_per_year = df['discharge_vol'].groupby(df['hydro_year']).apply(lambda x: x.isna().mean())\n",
    "\n",
    "    # Filter the DataFrame to only include years with less than the tolerance of missing values\n",
    "    df_filtered = df[df['hydro_year'].isin(missing_values_per_year[missing_values_per_year <= tolerance].index)]\n",
    "\n",
    "    # Drop the 'hydro_year' column\n",
    "    df_filtered = df_filtered.drop(columns='hydro_year')\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac8ca4",
   "metadata": {
    "papermill": {
     "duration": 0.001858,
     "end_time": "2024-05-13T13:54:43.268777",
     "exception": false,
     "start_time": "2024-05-13T13:54:43.266919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `q_mean` and `runoff_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf14af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:54:43.273334Z",
     "iopub.status.busy": "2024-05-13T13:54:43.273197Z",
     "iopub.status.idle": "2024-05-13T13:55:46.669820Z",
     "shell.execute_reply": "2024-05-13T13:55:46.669267Z"
    },
    "papermill": {
     "duration": 63.405032,
     "end_time": "2024-05-13T13:55:46.675708",
     "exception": false,
     "start_time": "2024-05-13T13:54:43.270676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_mean</th>\n",
       "      <th>runoff_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE110000</th>\n",
       "      <td>1.46</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110010</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110020</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110030</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110040</th>\n",
       "      <td>1.04</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10580</th>\n",
       "      <td>1.07</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10590</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10600</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10610</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10620</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_mean  runoff_ratio\n",
       "DE110000    1.46          0.49\n",
       "DE110010    0.67          0.23\n",
       "DE110020    0.84          0.33\n",
       "DE110030    0.84          0.34\n",
       "DE110040    1.04          0.40\n",
       "...          ...           ...\n",
       "DEG10580    1.07          0.47\n",
       "DEG10590    0.90          0.41\n",
       "DEG10600    0.25          0.15\n",
       "DEG10610    0.45          0.25\n",
       "DEG10620    0.60          0.31\n",
       "\n",
       "[1460 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe to store results\n",
    "df_results = pd.DataFrame(index=camels_ids)\n",
    "\n",
    "for camels_id in camels_ids:\n",
    "    # get station data\n",
    "    df = pd.read_csv(f\"../output_data/camels_de/timeseries/CAMELS_DE_hydromet_timeseries_{camels_id}.csv\", index_col=0)\n",
    "\n",
    "    # filter complete hydro years\n",
    "    df = filter_complete_hydro_years(df, tolerance=0.05)\n",
    "\n",
    "    # q_mean and p_mean\n",
    "    q_mean = df[\"discharge_spec\"].mean()\n",
    "    p_mean = df[\"precipitation_mean\"].mean()\n",
    "\n",
    "    # q_mean\n",
    "    df_results.loc[camels_id, \"q_mean\"] = round(q_mean, 2)\n",
    "\n",
    "    # runoff_ratio\n",
    "    df_results.loc[camels_id, \"runoff_ratio\"] = round(q_mean / p_mean, 2)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6829276e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:55:46.688892Z",
     "iopub.status.busy": "2024-05-13T13:55:46.688665Z",
     "iopub.status.idle": "2024-05-13T13:55:46.696064Z",
     "shell.execute_reply": "2024-05-13T13:55:46.695548Z"
    },
    "papermill": {
     "duration": 0.014473,
     "end_time": "2024-05-13T13:55:46.697645",
     "exception": false,
     "start_time": "2024-05-13T13:55:46.683172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_mean</th>\n",
       "      <th>runoff_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE111150</th>\n",
       "      <td>3.77</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE210710</th>\n",
       "      <td>4.15</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE214130</th>\n",
       "      <td>2.39</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE810130</th>\n",
       "      <td>2.63</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE910080</th>\n",
       "      <td>3.41</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEC10380</th>\n",
       "      <td>3.34</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEE10900</th>\n",
       "      <td>1.58</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_mean  runoff_ratio\n",
       "DE111150    3.77          1.70\n",
       "DE210710    4.15          1.02\n",
       "DE214130    2.39          1.02\n",
       "DE810130    2.63          1.61\n",
       "DE910080    3.41          1.45\n",
       "DEC10380    3.34          1.21\n",
       "DEE10900    1.58          1.01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results[\"runoff_ratio\"] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df30626",
   "metadata": {
    "papermill": {
     "duration": 0.00236,
     "end_time": "2024-05-13T13:55:46.703440",
     "exception": false,
     "start_time": "2024-05-13T13:55:46.701080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `flow_period_start`, `flow_period_end`, `flow_perc_complete`\n",
    "\n",
    "We also include the columns `flow_period_start`, `flow_period_end`, and `flow_perc_complete` from the file `CAMELS_GB_hydrometry_attributs.csv`, as we do not include uncertainty hydrometry attributes.\n",
    "\n",
    "**Here, we do not filter for complete hydrological years!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2b497d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:55:46.708840Z",
     "iopub.status.busy": "2024-05-13T13:55:46.708661Z",
     "iopub.status.idle": "2024-05-13T13:56:55.008721Z",
     "shell.execute_reply": "2024-05-13T13:56:55.008314Z"
    },
    "papermill": {
     "duration": 68.30605,
     "end_time": "2024-05-13T13:56:55.011709",
     "exception": false,
     "start_time": "2024-05-13T13:55:46.705659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_period_start</th>\n",
       "      <th>flow_period_end</th>\n",
       "      <th>flow_perc_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DE110000</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110010</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110020</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110030</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE110040</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10580</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10590</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10600</th>\n",
       "      <td>1961-11-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10610</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEG10620</th>\n",
       "      <td>1951-01-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         flow_period_start flow_period_end  flow_perc_complete\n",
       "DE110000        1951-01-01      2020-12-31                0.98\n",
       "DE110010        1951-01-01      2020-12-31                0.98\n",
       "DE110020        1951-01-01      2020-12-31                1.00\n",
       "DE110030        1951-01-01      2020-12-31                1.00\n",
       "DE110040        1951-01-01      2020-12-31                1.00\n",
       "...                    ...             ...                 ...\n",
       "DEG10580        1951-01-01      2020-12-31                1.00\n",
       "DEG10590        1951-01-01      2020-12-31                1.00\n",
       "DEG10600        1961-11-01      2020-12-31                0.85\n",
       "DEG10610        1951-01-01      2020-12-31                1.00\n",
       "DEG10620        1951-01-01      2020-12-31                0.99\n",
       "\n",
       "[1460 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for camels_id in camels_ids:\n",
    "    # get station data\n",
    "    df = pd.read_csv(f\"../output_data/camels_de/timeseries/CAMELS_DE_hydromet_timeseries_{camels_id}.csv\", index_col=0)\n",
    "\n",
    "    # parse dates\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # flow_period_start: first date in the timeseries where discharge_vol is not NaN\n",
    "    flow_period_start = df.index[df[\"discharge_vol\"].notnull()].min()\n",
    "    df_results.loc[camels_id, \"flow_period_start\"] = flow_period_start\n",
    "\n",
    "    # flow_period_end\n",
    "    flow_period_end = df.index[df[\"discharge_vol\"].notnull()].max()\n",
    "    df_results.loc[camels_id, \"flow_period_end\"] = flow_period_end\n",
    "\n",
    "    # flow_perc_complete: percentage of days with discharge_vol not NaN\n",
    "    flow_perc_complete = sum(df[\"discharge_vol\"].notnull()) / len(df)\n",
    "    df_results.loc[camels_id, \"flow_perc_complete\"] = round(flow_perc_complete, 2)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164007a3",
   "metadata": {
    "papermill": {
     "duration": 0.002273,
     "end_time": "2024-05-13T13:56:55.022070",
     "exception": false,
     "start_time": "2024-05-13T13:56:55.019797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `stream_elas`\n",
    "\n",
    "*streamflow precipitation elasticity (sensitivity of streamflow to changes in precipitation at the annual timescale, using the mean daily discharge as reference)*\n",
    "\n",
    "# https://github.com/camels-ch/camels/blob/master/hydro_climate_attributes/hydro_signatures.R\n",
    "\n",
    "\n",
    "**machen wir nicht**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc302e5",
   "metadata": {
    "papermill": {
     "duration": 0.002936,
     "end_time": "2024-05-13T13:56:55.027432",
     "exception": false,
     "start_time": "2024-05-13T13:56:55.024496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `slope_fdc`\n",
    "\n",
    "*slope of the flow duration curve (between the log-transformed 33rd and 66th streamflow percentiles)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16019133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T13:56:55.033489Z",
     "iopub.status.busy": "2024-05-13T13:56:55.033335Z",
     "iopub.status.idle": "2024-05-13T13:56:55.188888Z",
     "shell.execute_reply": "2024-05-13T13:56:55.188190Z"
    },
    "papermill": {
     "duration": 0.160359,
     "end_time": "2024-05-13T13:56:55.190596",
     "exception": true,
     "start_time": "2024-05-13T13:56:55.030237",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m p66 \u001b[38;5;241m=\u001b[39m df_fdc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdischarge_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.66\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# calculate the slope between the log-transformed 33rd and 66th percentiles\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m slope \u001b[38;5;241m=\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlog(p66) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(p33)) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m0.66\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.33\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# add to results\u001b[39;00m\n\u001b[1;32m     22\u001b[0m df_results\u001b[38;5;241m.\u001b[39mloc[camels_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslope_fdc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(slope, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for camels_id in camels_ids:\n",
    "    # get station data\n",
    "    df = pd.read_csv(f\"../output_data/camels_de/timeseries/CAMELS_DE_hydromet_timeseries_{camels_id}.csv\")\n",
    "\n",
    "    # make a new df with only the \"discharge_spec\" column\n",
    "    df_fdc = df[[\"discharge_spec\"]]\n",
    "\n",
    "    # drop NaN values\n",
    "    df_fdc = df_fdc.dropna()\n",
    "\n",
    "    # drop 0 values\n",
    "    df_fdc = df_fdc[df_fdc[\"discharge_spec\"] > 0]\n",
    "\n",
    "    # calculate the 33rd and 66th percentile\n",
    "    p33 = df_fdc[\"discharge_spec\"].quantile(0.33)\n",
    "    p66 = df_fdc[\"discharge_spec\"].quantile(0.66)\n",
    "\n",
    "    # calculate the slope between the log-transformed 33rd and 66th percentiles\n",
    "    slope = (np.log(p66) - np.log(p33)) / (0.66 - 0.33)\n",
    "\n",
    "    # add to results\n",
    "    df_results.loc[camels_id, \"slope_fdc\"] = round(slope, 2)\n",
    "    \n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64169c06",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### `hfd_mean`\n",
    "\n",
    "*mean half-flow date (date on which the cumulative discharge since 1 October reaches half of the annual discharge) [days since 1st October]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a12d5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for camels_id in camels_ids:\n",
    "    # get station data\n",
    "    df = pd.read_csv(f\"../output_data/camels_de/timeseries/CAMELS_DE_hydromet_timeseries_{camels_id}.csv\", index_col=0)\n",
    "\n",
    "    # filter complete hydro years\n",
    "    df = filter_complete_hydro_years(df, tolerance=0.05)\n",
    "\n",
    "    # add column for the water year\n",
    "    df['water_year'] = df.index.year\n",
    "    df.loc[df.index.month < 10, 'water_year'] -= 1\n",
    "\n",
    "    # calculate annual and half discharge\n",
    "    annual_discharge = df.groupby('water_year')['discharge_vol'].sum()\n",
    "    half_discharge = annual_discharge / 2\n",
    "\n",
    "    # calculate the cumulative discharge for each water year\n",
    "    df['cumulative_discharge'] = df.groupby('water_year')['discharge_vol'].cumsum()\n",
    "\n",
    "    # for each water year, find the date where the cumulative discharge first exceeds the half total discharge\n",
    "    df['exceeds_half'] = df.groupby('water_year')['cumulative_discharge'].transform(lambda x: x > half_discharge[x.name])\n",
    "    half_flow_dates = df[df['exceeds_half']].groupby('water_year')['exceeds_half'].idxmax()\n",
    "\n",
    "    # create a new DatetimeIndex representing October 1st of the water year\n",
    "    october_1st = pd.to_datetime(half_flow_dates.dt.year.astype(str) + '-10-01')\n",
    "    october_1st[half_flow_dates.dt.month < 10] = pd.to_datetime((half_flow_dates[half_flow_dates.dt.month < 10].dt.year - 1).astype(str) + '-10-01')\n",
    "\n",
    "    # subtract October 1st from each of these dates to get the number of days since October 1st\n",
    "    # add one day to include the end date in the calculation\n",
    "    days_since_october = (half_flow_dates - october_1st).dt.days + 1\n",
    "\n",
    "    # calculate the mean of these values\n",
    "    hfd_mean = days_since_october.mean()\n",
    "\n",
    "    # add to results\n",
    "    df_results.loc[camels_id, \"hfd_mean\"] = round(hfd_mean, 2)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d04a8d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### `Q5` and `Q95`\n",
    "\n",
    "- *5% flow quantile (low flow) [mm/day]*\n",
    "- *95% flow quantile (high flow)[mm/day]*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37037320",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for camels_id in camels_ids:\n",
    "    # get station data\n",
    "    df = pd.read_csv(f\"../output_data/camels_de/timeseries/CAMELS_DE_hydromet_timeseries_{camels_id}.csv\", index_col=0)\n",
    "\n",
    "    # filter complete hydro years\n",
    "    df = filter_complete_hydro_years(df, tolerance=0.05)\n",
    "\n",
    "    # discharge 5 and 95 percentile\n",
    "    q5 = df[\"discharge_spec\"].quantile(0.05)\n",
    "    q95 = df[\"discharge_spec\"].quantile(0.95)\n",
    "\n",
    "    # add to results\n",
    "    df_results.loc[camels_id, \"Q5\"] = round(q5, 2)\n",
    "    df_results.loc[camels_id, \"Q95\"] = round(q95, 2)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165a1cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### `high_q_freq`, `high_q_dur`, `low_q_freq`, `low_q_dur` and `zero_q_freq`\n",
    "\n",
    "- *frequency of high-flow days (> 9 times the median daily flow) [days/yr]*\n",
    "- *average duration of high flow events (number of consecutive days >9 times the median daily flow) [days]*\n",
    "- *frequency of low flow days (< 0.2 times the mean daily flow) [days/yr]*\n",
    "- *average duration of low flow events (number of consecutive days < 0.2 times the mean daily flow) [days]*\n",
    "- *frequency of days with Q = 0 [-]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d12e7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for camels_id in camels_ids:\n",
    "    # read camels de hydromet timeseries data\n",
    "    df = pd.read_csv(f\"../output_data/camels_de/timeseries/CAMELS_DE_hydromet_timeseries_{camels_id}.csv\")\n",
    "\n",
    "    # filter complete hydro years\n",
    "    df = filter_complete_hydro_years(df, tolerance=0.05)\n",
    "\n",
    "    # Time steps considered as high flows\n",
    "    hf = df[\"discharge_spec\"] > 9 * df[\"discharge_spec\"].median()\n",
    "\n",
    "    if hf.any():\n",
    "        # Mean duration of daily high flow events\n",
    "        # a string where 1 indicates a high flow event\n",
    "        hf_bin = ''.join(hf.astype(int).astype(str))\n",
    "        # Use str.split to isolate successive time steps with high discharge\n",
    "        hf_dur_noise = [len(s) for s in hf_bin.split('0')]\n",
    "        # Mean duration\n",
    "        high_q_dur = np.mean([d for d in hf_dur_noise if d > 0])\n",
    "\n",
    "        # Average number of daily high-flow events per year\n",
    "        high_q_freq = hf.sum() / len(df) * 365.25\n",
    "    else:\n",
    "        high_q_dur = 0\n",
    "        high_q_freq = 0\n",
    "\n",
    "    # Time steps considered as low flows\n",
    "    lf = df[\"discharge_spec\"] < 0.2 * df[\"discharge_spec\"].mean()\n",
    "\n",
    "    if lf.any():\n",
    "        # Mean duration of daily low flow events\n",
    "        # a string where 1 indicates a low flow event\n",
    "        lf_bin = ''.join(lf.astype(int).astype(str))\n",
    "        # Use str.split to isolate successive time steps with low discharge\n",
    "        lf_dur_noise = [len(s) for s in lf_bin.split('0')]\n",
    "        # Mean duration\n",
    "        low_q_dur = np.mean([d for d in lf_dur_noise if d > 0])\n",
    "\n",
    "        # Average number of daily low-flow events per year\n",
    "        low_q_freq = lf.sum() / len(df) * 365.25\n",
    "\n",
    "    # Ratio of time steps with zero discharge\n",
    "    zero_q_freq = df[\"discharge_spec\"].eq(0).mean()\n",
    "\n",
    "    # add to results\n",
    "    df_results.loc[camels_id, \"high_q_freq\"] = round(high_q_freq, 2)\n",
    "    df_results.loc[camels_id, \"high_q_dur\"] = round(high_q_dur, 2)\n",
    "    df_results.loc[camels_id, \"low_q_freq\"] = round(low_q_freq, 2)\n",
    "    df_results.loc[camels_id, \"low_q_dur\"] = round(low_q_dur, 2)\n",
    "    df_results.loc[camels_id, \"zero_q_freq\"] = round(zero_q_freq, 2)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdb2bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f99bb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "df_results.to_csv(\"../output_data/camels_de/CAMELS_DE_hydrologic_attributes.csv\", index_label=\"gauge_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 133.08675,
   "end_time": "2024-05-13T13:56:55.417043",
   "environment_variables": {},
   "exception": true,
   "input_path": "/scripts/08_hydrologic_attributes.ipynb",
   "output_path": "/output_data/scripts/08_hydrologic_attributes.ipynb",
   "parameters": {},
   "start_time": "2024-05-13T13:54:42.330293",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
